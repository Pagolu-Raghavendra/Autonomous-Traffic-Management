{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b45cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (8.3.40)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2022.11.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6623a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda01247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ultralytics in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (8.3.40)\n",
      "Requirement already satisfied: deep-sort-realtime in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (1.3.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.10.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.7.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2022.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ragha\\appdata\\roaming\\python\\python310\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics deep-sort-realtime opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0dc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Loading YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Define vehicle classes (COCO dataset IDs for vehicles)\n",
    "vehicle_classes = [2, 3, 5, 7]  # Car, Bus, Truck, Motorcycle\n",
    "\n",
    "# Variables for waiting zone\n",
    "waiting_zone = []\n",
    "zone_defined = False  # Flag to check if the zone is defined\n",
    "\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    \"\"\"\n",
    "    Mouse callback to define the waiting zone by clicking.\n",
    "    \"\"\"\n",
    "    global waiting_zone, zone_defined\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and not zone_defined:\n",
    "        if len(waiting_zone) < 4:\n",
    "            waiting_zone.append((x, y))\n",
    "            print(f\"Point {len(waiting_zone)} added: {x}, {y}\")\n",
    "        if len(waiting_zone) == 4:\n",
    "            print(\"Waiting zone defined.\")\n",
    "            zone_defined = True\n",
    "\n",
    "\n",
    "# Opening video stream\n",
    "cap = cv2.VideoCapture(\"Lane1.mp4\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video source.\")\n",
    "    exit()\n",
    "\n",
    "# Creating a named window and set the mouse callback\n",
    "cv2.namedWindow(\"Traffic Waiting Zone\")\n",
    "cv2.setMouseCallback(\"Traffic Waiting Zone\", mouse_callback)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video stream or cannot read frame.\")\n",
    "        break\n",
    "\n",
    "    # Showing frame for defining waiting zone\n",
    "    if not zone_defined:\n",
    "        for point in waiting_zone:\n",
    "            cv2.circle(frame, point, 5, (0, 0, 255), -1)\n",
    "        if len(waiting_zone) > 1:\n",
    "            cv2.polylines(frame, [np.array(waiting_zone)], isClosed=False, color=(0, 0, 255), thickness=2)\n",
    "        cv2.imshow(\"Traffic Waiting Zone\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # Draw the waiting zone\n",
    "    if zone_defined and len(waiting_zone) == 4:\n",
    "        cv2.polylines(frame, [np.array(waiting_zone)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "    # Run YOLOv8 inference\n",
    "    results = model(frame, stream=False, verbose=False)\n",
    "\n",
    "    # Reset vehicle count for each frame\n",
    "    vehicle_count = 0\n",
    "\n",
    "    # Loop through detections\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls.cpu().numpy().item())\n",
    "            if cls_id in vehicle_classes:  # Checking if it's a vehicle\n",
    "                x, y, w, h = map(int, box.xywh.cpu().numpy()[0])\n",
    "                x1, y1 = x - w // 2, y - h // 2\n",
    "                x2, y2 = x + w // 2, y + h // 2\n",
    "\n",
    "                # Checking if the vehicle is in the waiting zone\n",
    "                if zone_defined and cv2.pointPolygonTest(np.array(waiting_zone), (x, y), False) >= 0:\n",
    "                    vehicle_count += 1\n",
    "\n",
    "                # Drawing the bounding box and label\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Vehicle\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5, (0, 255, 255), 2)\n",
    "\n",
    "    # Displaying vehicle count\n",
    "    cv2.putText(frame, f\"Waiting Vehicles: {vehicle_count}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 0, 0), 2)\n",
    "\n",
    "    # Showing the frame\n",
    "    cv2.imshow(\"Traffic Waiting Zone\", frame)\n",
    "\n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f81d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¦LANE_1 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_1 GREEN for 56 seconds. Vehicles: 28\n",
      "ðŸš¦LANE_1 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_3 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_3 GREEN for 60 seconds. Vehicles: 31\n",
      "ðŸš¦LANE_3 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_4 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_4 GREEN for 36 seconds. Vehicles: 18\n",
      "ðŸš¦LANE_4 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_2 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_2 GREEN for 18 seconds. Vehicles: 9\n",
      "Cycle complete. Starting over...\n",
      "ðŸš¦LANE_2 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_1 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_1 GREEN for 60 seconds. Vehicles: 30\n"
     ]
    }
   ],
   "source": [
    "'''Without Ambulance'''\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import threading\n",
    "\n",
    "# Loading YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "#Loading ambulance trained model \n",
    "ambulance_model = YOLO(\"C:/Users/ragha/runs/detect/train5/weights/best.pt\")\n",
    "\n",
    "# Defining vehicle classes (COCO dataset IDs for vehicles)\n",
    "vehicle_classes = [2, 3, 5, 7]  # Car, Bus, Truck, Motorcycle\n",
    "\n",
    "# Initializing variables for lane monitoring\n",
    "lanes = {\n",
    "    \"lane_1\": {\"cctv\": \"Lane1.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_2\": {\"cctv\": \"Lane2.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_3\": {\"cctv\": \"Lane3.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_4\": {\"cctv\": \"Lane4.mp4\", \"count\": 0, \"ambulance_detected\": False}\n",
    "}\n",
    "\n",
    "# Signal states and timers\n",
    "signal_states = {\"lane_1\": \"red\", \"lane_2\": \"red\", \"lane_3\": \"red\", \"lane_4\": \"red\"}\n",
    "signal_timers = {\"lane_1\": 0, \"lane_2\": 0, \"lane_3\": 0, \"lane_4\": 0}\n",
    "\n",
    "# Flag to stop the process\n",
    "stop_process = False\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "caps = {lane_key: cv2.VideoCapture(lanes[lane_key][\"cctv\"]) for lane_key in lanes.keys()}\n",
    "for cap in caps.values():\n",
    "        cap.set(cv2.CAP_PROP_FPS, 1200)\n",
    "\n",
    "def count_vehicles_and_draw(frame, lane_key):\n",
    "    \"\"\"\n",
    "    Detect and count vehicles in the frame using YOLO, and draw bounding boxes.\n",
    "    \"\"\"\n",
    "    results = model(frame, stream=False, verbose=False)\n",
    "    vehicle_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls.cpu().numpy().item())\n",
    "            if cls_id in vehicle_classes:  # Checking if the detected object is a vehicle\n",
    "                vehicle_count += 1\n",
    "\n",
    "                # Drawing bounding box\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    model.names[cls_id],\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "    with lock:\n",
    "        lanes[lane_key][\"count\"] = vehicle_count\n",
    "    return frame\n",
    "\n",
    "\n",
    "def process_lane():\n",
    "    \"\"\"\n",
    "    Process each lane's CCTV feed and update vehicle counts with detection frames.\n",
    "    \"\"\"\n",
    "    for lane_key in ['lane_1','lane_2','lane_3', 'lane_4']:\n",
    "        cap =cv2.VideoCapture(lanes[lane_key][\"cctv\"])\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = count_vehicles_and_draw(frame, lane_key)\n",
    "        else:\n",
    "            frame = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"No feed for {lane_key.upper()}\",\n",
    "                (50, 150),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "            )\n",
    "        cap.release()\n",
    "        return frame\n",
    "\n",
    "\n",
    "def display_signals():\n",
    "    \"\"\"\n",
    "    Display the current traffic signal status for all lanes along with timers.\n",
    "    \"\"\"\n",
    "    global next_signal, reason\n",
    "    signal_image = np.zeros((300, 650, 3), dtype=np.uint8)\n",
    "\n",
    "    positions = {\n",
    "        \"lane_1\": (50, 30),\n",
    "        \"lane_2\": (50, 70),\n",
    "        \"lane_3\": (50, 110),\n",
    "        \"lane_4\": (50, 150),\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        \"red\": (0, 0, 255),\n",
    "        \"green\": (0, 255, 0),\n",
    "        \"yellow\": (0, 255, 255),\n",
    "    }\n",
    "\n",
    "    # Determining the next lane with the highest vehicle count\n",
    "    next_lane = next_signal\n",
    "    next_note = f\"Next GREEN: {next_lane.upper()} {reason}\"\n",
    "    \n",
    "    for lane, state in signal_states.items():\n",
    "        pos = positions[lane]\n",
    "        color = colors[state]\n",
    "        timer = signal_timers[lane]\n",
    "        text = f\"{lane.upper()}: {state.upper()} - {timer}s\"\n",
    "        cv2.putText(signal_image, text, (pos[0], pos[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "    # Adding the note for the next green signal\n",
    "    cv2.putText(signal_image, next_note, (50, 230), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Traffic Signals\", signal_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        global stop_process\n",
    "        stop_process = True\n",
    "\n",
    "\n",
    "def transition_to_yellow(lane_key):\n",
    "    \"\"\"\n",
    "    Transition a lane's signal to yellow for 5 seconds.\n",
    "    \"\"\"\n",
    "    global signal_states, signal_timers\n",
    "    signal_states[lane_key] = \"yellow\"\n",
    "    signal_timers[lane_key] = 5\n",
    "    print(f\"ðŸš¦{lane_key.upper()} YELLOW for 5 seconds.\")\n",
    "    while signal_timers[lane_key] > 0:\n",
    "        display_signals()\n",
    "        time.sleep(1)\n",
    "        signal_timers[lane_key] -= 1\n",
    "\n",
    "\n",
    "def manage_signals():\n",
    "    \"\"\"\n",
    "    Manage traffic signals based on vehicle counts.\n",
    "    \"\"\"\n",
    "    global lanes, signal_states, signal_timers, stop_process, next_signal, current_green, reason\n",
    "    while not stop_process:\n",
    "        # Sorting lanes by vehicle count and manage signals\n",
    "        reason=\"More Vehicles\"\n",
    "        flag=0\n",
    "        lanes_data=copy.deepcopy(lanes)\n",
    "        data=list(lanes_data)\n",
    "        while flag<4:\n",
    "            vehicount={}\n",
    "            flag=flag+1\n",
    "            for lane_key in lanes_data.keys():\n",
    "                vehicount[lane_key]=lanes[lane_key][\"count\"]\n",
    "            lane= max(vehicount, key=vehicount.get)\n",
    "            next_signal=lane\n",
    "            reason=\"More Vehicles\"\n",
    "            vehicle_count = vehicount[lane]\n",
    "            del lanes_data[lane]\n",
    "            if vehicle_count > 0:\n",
    "                green_time = min(max(10, vehicle_count * 2), 60)  # Green time limits\n",
    "\n",
    "                # Turning other signals to red\n",
    "                for other_lane in signal_states:\n",
    "                    if other_lane != lane and signal_states[other_lane] != \"red\":\n",
    "                        transition_to_yellow(other_lane)\n",
    "                        signal_states[other_lane] = \"red\"\n",
    "\n",
    "                # Transition from red to green\n",
    "                if signal_states[lane] == \"red\":\n",
    "                    transition_to_yellow(lane)\n",
    "                    signal_states[lane] = \"green\"\n",
    "                    reason=\"\"\n",
    "                    next_signal=\"\"\n",
    "                    signal_timers[lane] = green_time\n",
    "                current_green=lane\n",
    "                print(f\"ðŸš¦{lane.upper()} GREEN for {green_time} seconds. Vehicles: {vehicle_count}\")\n",
    "                while signal_timers[lane] > 0:\n",
    "                    display_signals()\n",
    "                    time.sleep(1)\n",
    "                    signal_timers[lane] -= 1\n",
    "                    prev_time=signal_timers[lane]\n",
    "                    for lane_key in lanes.keys():\n",
    "                        if lanes[lane_key][\"ambulance_detected\"]:\n",
    "                            next_signal=lane_key\n",
    "                            reason=\"Ambulance\"\n",
    "                            prioritize_ambulane_lane(lane_key)\n",
    "                            if stop_process:\n",
    "                                return\n",
    "                            next_signal=lane\n",
    "                            reason=\"More Vehicles\"\n",
    "                            transition_to_yellow(lane)\n",
    "                            current_green=lane\n",
    "                    signal_timers[lane]=prev_time\n",
    "                    signal_states[lane] = \"green\"\n",
    "                    next_signal=\"\"\n",
    "                    reason=\"\"\n",
    "                    if stop_process:\n",
    "                        return\n",
    "\n",
    "                if stop_process:\n",
    "                    return\n",
    "            else:\n",
    "                print(f\"ðŸš¦{lane.upper()} YELLOW for 5 seconds (No vehicles detected).\")\n",
    "                transition_to_yellow(lane)\n",
    "                signal_states[lane] = \"red\"\n",
    "\n",
    "                if stop_process:\n",
    "                    return\n",
    "\n",
    "        print(\"Cycle complete. Starting over...\")\n",
    "\n",
    "def prioritize_ambulane_lane(lane):\n",
    "    global signal_states, signal_timers, next_signal, current_green, lanes, reason\n",
    "    if current_green==lane:\n",
    "        signal_timers[lane]=signal_timers[lane]+30\n",
    "        lanes[lane][\"ambulance_detected\"]=False\n",
    "        return\n",
    "    else:\n",
    "        # Turning other signals to red\n",
    "        for other_lane in signal_states:\n",
    "            if other_lane != lane and signal_states[other_lane] != \"red\":\n",
    "                transition_to_yellow(other_lane)\n",
    "                signal_states[other_lane] = \"red\"\n",
    "        # Transition from red to green\n",
    "        if signal_states[lane] == \"red\":\n",
    "            transition_to_yellow(lane)\n",
    "            print(f\"ðŸš¦{lane.upper()} GREEN for ambulance\")\n",
    "            current_green=lane\n",
    "            signal_states[lane] = \"green\"\n",
    "            signal_timers[lane] = 30\n",
    "            reason=\"\"\n",
    "            next_signal=\"\"\n",
    "        while signal_timers[lane] > 0:\n",
    "            display_signals()\n",
    "            time.sleep(1)\n",
    "            signal_timers[lane] -= 1\n",
    "            if stop_process:\n",
    "                return\n",
    "        lanes[lane][\"ambulance_detected\"]=False\n",
    "        transition_to_yellow(lane)\n",
    "        signal_states[lane]=\"red\"\n",
    "        signal_timers[lane]=0\n",
    "        return\n",
    "        \n",
    "\n",
    "def detect_ambulance(frame, lane_key, confidence_threshold=0.7):\n",
    "    if lanes[lane_key][\"ambulance_detected\"]:\n",
    "        results = ambulance_model(frame,verbose=False)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                cls_id = int(box.cls.cpu().numpy().item())\n",
    "                class_name = ambulance_model.names[cls_id]\n",
    "                if class_name.lower() == \"ambulance\" and box.conf.cpu().numpy() > confidence_threshold:\n",
    "                    # Drawing the bounding box on the frame for ambulance\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"Ambulance\",\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.9,\n",
    "                        (0, 0, 255),\n",
    "                        2,\n",
    "                    )\n",
    "        return frame\n",
    "    else:\n",
    "        results = ambulance_model(frame,verbose=False)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                cls_id = int(box.cls.cpu().numpy().item())\n",
    "                class_name = ambulance_model.names[cls_id]\n",
    "                if class_name.lower() == \"ambulance\" and box.conf.cpu().numpy() > confidence_threshold:\n",
    "                    lanes[lane_key][\"ambulance_detected\"] = True\n",
    "                    print(f\"ðŸš‘ Ambulance detected in {lane_key}! Prioritizing this lane.\")\n",
    "                    # Drawing the bounding box on the frame for ambulance\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"Ambulance\",\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.9,\n",
    "                        (0, 0, 255),\n",
    "                        2,\n",
    "                    )\n",
    "        return frame\n",
    "    \n",
    "            \n",
    "def display_cameras():\n",
    "    \"\"\"\n",
    "    Display all 4 CCTV feeds in one frame.\n",
    "    \"\"\"\n",
    "    global stop_process, caps\n",
    "\n",
    "    lane_labels = {\n",
    "        \"lane_1\": \"Lane 1\",\n",
    "        \"lane_2\": \"Lane 2\",\n",
    "        \"lane_3\": \"Lane 3\",\n",
    "        \"lane_4\": \"Lane 4\",\n",
    "    }\n",
    "    \n",
    "    while not stop_process:\n",
    "        frames = []\n",
    "        for lane_key, cap in caps.items():\n",
    "            for _ in range(10):\n",
    "                cap.grab()\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Adding lane label to the frame\n",
    "                label = lane_labels[lane_key]\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    label,\n",
    "                    (10, 55),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,  \n",
    "                    (0, 255, 255),  \n",
    "                    4,  \n",
    "                )\n",
    "                frame = count_vehicles_and_draw(frame, lane_key)\n",
    "                frame= detect_ambulance(frame, lane_key)\n",
    "            else:\n",
    "                # If video ends or fails, display a placeholder\n",
    "                frame = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    \"No feed\",\n",
    "                    (50, 150),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (0, 0, 255),\n",
    "                    4,\n",
    "                )\n",
    "                stop_process = True\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        # Resizing frames to fit in a single window\n",
    "        resized_frames = [cv2.resize(f, (400, 300)) for f in frames]\n",
    "        row1 = np.hstack(resized_frames[:2])  \n",
    "        row2 = np.hstack(resized_frames[2:])  \n",
    "        combined_frame = np.vstack([row1, row2])\n",
    "\n",
    "        cv2.imshow(\"All CCTV Feeds\", combined_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            stop_process = True\n",
    "            break\n",
    "\n",
    "    # Release video captures and close windows\n",
    "    for cap in caps.values():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main loop to monitor traffic and manage signals.\n",
    "    \"\"\"\n",
    "    global stop_process\n",
    "    process_lane()\n",
    "    # Start threads for camera display and signal management\n",
    "    camera_thread = threading.Thread(target=display_cameras)\n",
    "    signal_thread = threading.Thread(target=manage_signals)\n",
    "\n",
    "    camera_thread.start()\n",
    "    signal_thread.start()\n",
    "\n",
    "    camera_thread.join()\n",
    "    signal_thread.join()\n",
    "\n",
    "    print(\"Process stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¦LANE_1 YELLOW for 5 seconds.\n",
      "ðŸš‘ Ambulance detected in lane_2! Prioritizing this lane.\n",
      "ðŸš¦LANE_1 GREEN for 58 seconds. Vehicles: 29\n",
      "ðŸš¦LANE_1 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_2 YELLOW for 5 seconds.\n",
      "ðŸš¦LANE_2 GREEN for ambulance\n"
     ]
    }
   ],
   "source": [
    "'''With Ambulance'''\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import threading\n",
    "\n",
    "# Loading YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\") \n",
    "\n",
    "#Loading ambulance trained model \n",
    "ambulance_model = YOLO(\"C:/Users/ragha/runs/detect/train5/weights/best.pt\")\n",
    "\n",
    "# Defining vehicle classes (COCO dataset IDs for vehicles)\n",
    "vehicle_classes = [2, 3, 5, 7]  # Car, Bus, Truck, Motorcycle\n",
    "\n",
    "# Initializing variables for lane monitoring\n",
    "lanes = {\n",
    "    \"lane_1\": {\"cctv\": \"A1.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_2\": {\"cctv\": \"A2.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_3\": {\"cctv\": \"Lane3.mp4\", \"count\": 0, \"ambulance_detected\": False},\n",
    "    \"lane_4\": {\"cctv\": \"Lane4.mp4\", \"count\": 0, \"ambulance_detected\": False}\n",
    "}\n",
    "\n",
    "# Signal states and timers\n",
    "signal_states = {\"lane_1\": \"red\", \"lane_2\": \"red\", \"lane_3\": \"red\", \"lane_4\": \"red\"}\n",
    "signal_timers = {\"lane_1\": 0, \"lane_2\": 0, \"lane_3\": 0, \"lane_4\": 0}\n",
    "\n",
    "# Flag to stop the process\n",
    "stop_process = False\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "caps = {lane_key: cv2.VideoCapture(lanes[lane_key][\"cctv\"]) for lane_key in lanes.keys()}\n",
    "for cap in caps.values():\n",
    "        cap.set(cv2.CAP_PROP_FPS, 1200)\n",
    "\n",
    "def count_vehicles_and_draw(frame, lane_key):\n",
    "    \"\"\"\n",
    "    Detect and count vehicles in the frame using YOLO, and draw bounding boxes.\n",
    "    \"\"\"\n",
    "    results = model(frame, stream=False, verbose=False)\n",
    "    vehicle_count = 0\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls.cpu().numpy().item())\n",
    "            if cls_id in vehicle_classes:  # Checking if the detected object is a vehicle\n",
    "                vehicle_count += 1\n",
    "\n",
    "                # Drawing bounding box\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    model.names[cls_id],\n",
    "                    (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "    with lock:\n",
    "        lanes[lane_key][\"count\"] = vehicle_count\n",
    "    return frame\n",
    "\n",
    "\n",
    "def process_lane():\n",
    "    \"\"\"\n",
    "    Process each lane's CCTV feed and update vehicle counts with detection frames.\n",
    "    \"\"\"\n",
    "    for lane_key in ['lane_1','lane_2','lane_3', 'lane_4']:\n",
    "        cap =cv2.VideoCapture(lanes[lane_key][\"cctv\"])\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = count_vehicles_and_draw(frame, lane_key)\n",
    "        else:\n",
    "            frame = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"No feed for {lane_key.upper()}\",\n",
    "                (50, 150),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "            )\n",
    "        cap.release()\n",
    "        return frame\n",
    "\n",
    "\n",
    "def display_signals():\n",
    "    \"\"\"\n",
    "    Display the current traffic signal status for all lanes along with timers.\n",
    "    \"\"\"\n",
    "    global next_signal, reason\n",
    "    signal_image = np.zeros((300, 650, 3), dtype=np.uint8)\n",
    "\n",
    "    positions = {\n",
    "        \"lane_1\": (50, 30),\n",
    "        \"lane_2\": (50, 70),\n",
    "        \"lane_3\": (50, 110),\n",
    "        \"lane_4\": (50, 150),\n",
    "    }\n",
    "\n",
    "    colors = {\n",
    "        \"red\": (0, 0, 255),\n",
    "        \"green\": (0, 255, 0),\n",
    "        \"yellow\": (0, 255, 255),\n",
    "    }\n",
    "\n",
    "    # Determining the next lane with the highest vehicle count\n",
    "    next_lane = next_signal\n",
    "    next_note = f\"Next GREEN: {next_lane.upper()} {reason}\"\n",
    "    \n",
    "    for lane, state in signal_states.items():\n",
    "        pos = positions[lane]\n",
    "        color = colors[state]\n",
    "        timer = signal_timers[lane]\n",
    "        text = f\"{lane.upper()}: {state.upper()} - {timer}s\"\n",
    "        cv2.putText(signal_image, text, (pos[0], pos[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "    # Adding the note for the next green signal\n",
    "    cv2.putText(signal_image, next_note, (50, 230), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Traffic Signals\", signal_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        global stop_process\n",
    "        stop_process = True\n",
    "\n",
    "\n",
    "def transition_to_yellow(lane_key):\n",
    "    \"\"\"\n",
    "    Transition a lane's signal to yellow for 5 seconds.\n",
    "    \"\"\"\n",
    "    global signal_states, signal_timers\n",
    "    signal_states[lane_key] = \"yellow\"\n",
    "    signal_timers[lane_key] = 5\n",
    "    print(f\"ðŸš¦{lane_key.upper()} YELLOW for 5 seconds.\")\n",
    "    while signal_timers[lane_key] > 0:\n",
    "        display_signals()\n",
    "        time.sleep(1)\n",
    "        signal_timers[lane_key] -= 1\n",
    "\n",
    "\n",
    "def manage_signals():\n",
    "    \"\"\"\n",
    "    Manage traffic signals based on vehicle counts.\n",
    "    \"\"\"\n",
    "    global lanes, signal_states, signal_timers, stop_process, next_signal, current_green, reason\n",
    "    while not stop_process:\n",
    "        # Sorting lanes by vehicle count and manage signals\n",
    "        reason=\"More Vehicles\"\n",
    "        flag=0\n",
    "        lanes_data=copy.deepcopy(lanes)\n",
    "        data=list(lanes_data)\n",
    "        while flag<4:\n",
    "            vehicount={}\n",
    "            flag=flag+1\n",
    "            for lane_key in lanes_data.keys():\n",
    "                vehicount[lane_key]=lanes[lane_key][\"count\"]\n",
    "            lane= max(vehicount, key=vehicount.get)\n",
    "            next_signal=lane\n",
    "            reason=\"More Vehicles\"\n",
    "            vehicle_count = vehicount[lane]\n",
    "            del lanes_data[lane]\n",
    "            if vehicle_count > 0:\n",
    "                green_time = min(max(10, vehicle_count * 2), 60)  # Green time limits\n",
    "\n",
    "                # Turning other signals to red\n",
    "                for other_lane in signal_states:\n",
    "                    if other_lane != lane and signal_states[other_lane] != \"red\":\n",
    "                        transition_to_yellow(other_lane)\n",
    "                        signal_states[other_lane] = \"red\"\n",
    "\n",
    "                # Transition from red to green\n",
    "                if signal_states[lane] == \"red\":\n",
    "                    transition_to_yellow(lane)\n",
    "                    signal_states[lane] = \"green\"\n",
    "                    reason=\"\"\n",
    "                    next_signal=\"\"\n",
    "                    signal_timers[lane] = green_time\n",
    "                current_green=lane\n",
    "                print(f\"ðŸš¦{lane.upper()} GREEN for {green_time} seconds. Vehicles: {vehicle_count}\")\n",
    "                while signal_timers[lane] > 0:\n",
    "                    display_signals()\n",
    "                    time.sleep(1)\n",
    "                    signal_timers[lane] -= 1\n",
    "                    prev_time=signal_timers[lane]\n",
    "                    for lane_key in lanes.keys():\n",
    "                        if lanes[lane_key][\"ambulance_detected\"]:\n",
    "                            next_signal=lane_key\n",
    "                            reason=\"Ambulance\"\n",
    "                            prioritize_ambulane_lane(lane_key)\n",
    "                            if stop_process:\n",
    "                                return\n",
    "                            next_signal=lane\n",
    "                            reason=\"More Vehicles\"\n",
    "                            transition_to_yellow(lane)\n",
    "                            current_green=lane\n",
    "                    signal_timers[lane]=prev_time\n",
    "                    signal_states[lane] = \"green\"\n",
    "                    next_signal=\"\"\n",
    "                    reason=\"\"\n",
    "                    if stop_process:\n",
    "                        return\n",
    "\n",
    "                if stop_process:\n",
    "                    return\n",
    "            else:\n",
    "                print(f\"ðŸš¦{lane.upper()} YELLOW for 5 seconds (No vehicles detected).\")\n",
    "                transition_to_yellow(lane)\n",
    "                signal_states[lane] = \"red\"\n",
    "\n",
    "                if stop_process:\n",
    "                    return\n",
    "\n",
    "        print(\"Cycle complete. Starting over...\")\n",
    "\n",
    "def prioritize_ambulane_lane(lane):\n",
    "    global signal_states, signal_timers, next_signal, current_green, lanes, reason\n",
    "    if current_green==lane:\n",
    "        signal_timers[lane]=signal_timers[lane]+30\n",
    "        lanes[lane][\"ambulance_detected\"]=False\n",
    "        return\n",
    "    else:\n",
    "        # Turning other signals to red\n",
    "        for other_lane in signal_states:\n",
    "            if other_lane != lane and signal_states[other_lane] != \"red\":\n",
    "                transition_to_yellow(other_lane)\n",
    "                signal_states[other_lane] = \"red\"\n",
    "        # Transition from red to green\n",
    "        if signal_states[lane] == \"red\":\n",
    "            transition_to_yellow(lane)\n",
    "            print(f\"ðŸš¦{lane.upper()} GREEN for ambulance\")\n",
    "            current_green=lane\n",
    "            signal_states[lane] = \"green\"\n",
    "            signal_timers[lane] = 30\n",
    "            reason=\"\"\n",
    "            next_signal=\"\"\n",
    "        while signal_timers[lane] > 0:\n",
    "            display_signals()\n",
    "            time.sleep(1)\n",
    "            signal_timers[lane] -= 1\n",
    "            if stop_process:\n",
    "                return\n",
    "        lanes[lane][\"ambulance_detected\"]=False\n",
    "        transition_to_yellow(lane)\n",
    "        signal_states[lane]=\"red\"\n",
    "        signal_timers[lane]=0\n",
    "        return\n",
    "        \n",
    "\n",
    "def detect_ambulance(frame, lane_key, confidence_threshold=0.7):\n",
    "    if lanes[lane_key][\"ambulance_detected\"]:\n",
    "        results = ambulance_model(frame,verbose=False)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                cls_id = int(box.cls.cpu().numpy().item())\n",
    "                class_name = ambulance_model.names[cls_id]\n",
    "                if class_name.lower() == \"ambulance\" and box.conf.cpu().numpy() > confidence_threshold:\n",
    "                    # Drawing the bounding box on the frame for ambulance\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"Ambulance\",\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.9,\n",
    "                        (0, 0, 255),\n",
    "                        2,\n",
    "                    )\n",
    "        return frame\n",
    "    else:\n",
    "        results = ambulance_model(frame,verbose=False)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                cls_id = int(box.cls.cpu().numpy().item())\n",
    "                class_name = ambulance_model.names[cls_id]\n",
    "                if class_name.lower() == \"ambulance\" and box.conf.cpu().numpy() > confidence_threshold:\n",
    "                    lanes[lane_key][\"ambulance_detected\"] = True\n",
    "                    print(f\"ðŸš‘ Ambulance detected in {lane_key}! Prioritizing this lane.\")\n",
    "                    # Drawing the bounding box on the frame for ambulance\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy()[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        \"Ambulance\",\n",
    "                        (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.9,\n",
    "                        (0, 0, 255),\n",
    "                        2,\n",
    "                    )\n",
    "        return frame\n",
    "    \n",
    "            \n",
    "def display_cameras():\n",
    "    \"\"\"\n",
    "    Display all 4 CCTV feeds in one frame.\n",
    "    \"\"\"\n",
    "    global stop_process, caps\n",
    "\n",
    "    lane_labels = {\n",
    "        \"lane_1\": \"Lane 1\",\n",
    "        \"lane_2\": \"Lane 2\",\n",
    "        \"lane_3\": \"Lane 3\",\n",
    "        \"lane_4\": \"Lane 4\",\n",
    "    }\n",
    "    \n",
    "    while not stop_process:\n",
    "        frames = []\n",
    "        for lane_key, cap in caps.items():\n",
    "            for _ in range(10):\n",
    "                cap.grab()\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Adding lane label to the frame\n",
    "                label = lane_labels[lane_key]\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    label,\n",
    "                    (10, 55),  \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,  \n",
    "                    (0, 255, 255),  \n",
    "                    4,  \n",
    "                )\n",
    "                frame = count_vehicles_and_draw(frame, lane_key)\n",
    "                frame= detect_ambulance(frame, lane_key)\n",
    "            else:\n",
    "                # If video ends or fails, display a placeholder\n",
    "                frame = np.zeros((300, 400, 3), dtype=np.uint8)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    \"No feed\",\n",
    "                    (50, 150),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2,\n",
    "                    (0, 0, 255),\n",
    "                    4,\n",
    "                )\n",
    "                stop_process = True\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        # Resizing frames to fit in a single window\n",
    "        resized_frames = [cv2.resize(f, (400, 300)) for f in frames]\n",
    "        row1 = np.hstack(resized_frames[:2])  \n",
    "        row2 = np.hstack(resized_frames[2:])  \n",
    "        combined_frame = np.vstack([row1, row2])\n",
    "\n",
    "        cv2.imshow(\"All CCTV Feeds\", combined_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            stop_process = True\n",
    "            break\n",
    "\n",
    "    # Release video captures and close windows\n",
    "    for cap in caps.values():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main loop to monitor traffic and manage signals.\n",
    "    \"\"\"\n",
    "    global stop_process\n",
    "    process_lane()\n",
    "    # Start threads for camera display and signal management\n",
    "    camera_thread = threading.Thread(target=display_cameras)\n",
    "    signal_thread = threading.Thread(target=manage_signals)\n",
    "\n",
    "    camera_thread.start()\n",
    "    signal_thread.start()\n",
    "\n",
    "    camera_thread.join()\n",
    "    signal_thread.join()\n",
    "\n",
    "    print(\"Process stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fd6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
